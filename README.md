# TableNet Experiment Code for Reproduction
Official code of  experiment in TableNet: A Large-Scale Table Dataset with LLM-Powered Autonomous Generation

## Training Qwen2-VL-2B
Traing and inferencing splits in conversation format can generated by running code below respectively for training on TableNet and PubTabNet. And these are some extra functions in preprocess_pubtabnet.py for 1) filtering conversations with img_path containing 'crawl' in TableNet test set, which is real-world data. 2) sampling a subset of the PubTabNet dataset, keep the training dataset size the same as training on our TableNet
```
python preprocess.py
python preprocess_pubtabnet.py
```
Notably, you should set to proper path on your machine.
```
generation_dir = "PATH TO GENERATION DATA/"
opensource_dir = "PATH TO OPENDATA/"
crawl_dir = "PATH TO CRAWLED DATA/"
```
Then you can train Qwen2-VL-2B by running, you can specify training dataset using generate data mentioned above.
```
python main.py
```
We uploaded our trained model on HF:


## Inference with trained model and other baselines
To get 2B result, set finetuned model path correctly
```
finetuned_model_path = "PATH TO TRAINED MODEL"
```
and then run
```
python test_main.py
```
For baseline results, run
```
python api_inference.py
```
This code needs 3 api keys, DASHSCOPE for Qwen series, yunwu.ai for GPT and superbed for url generation. Superbed api key is provided for reproduction.

Other experiment codes are available alongside the agent code in supplementary materials and well commented.


